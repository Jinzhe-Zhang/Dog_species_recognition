{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5))\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "base_dir = './dogImages'\n",
    "train_dir = os.path.join(base_dir, 'train_plus')\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增强数据集的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists(train_plus_dir):\n",
    "#     shutil.copytree(train_dir,train_plus_dir)\n",
    "# for kind in os.listdir(train_plus_dir):\n",
    "#     kind_dir=os.path.join(train_plus_dir, kind)\n",
    "#     if len(os.listdir(kind_dir))*4 < 5*len([x for x in os.listdir(kind_dir) if x.startswith('pic_plus')])+5:\n",
    "#         continue\n",
    "#     for pic in os.listdir(kind_dir):\n",
    "#         pic_dir=os.path.join(kind_dir, pic)\n",
    "#         if not pic.endswith(\".jpg\"):\n",
    "#             continue\n",
    "#         if pic.startswith('pic_plus'):\n",
    "#             os.remove(pic_dir)\n",
    "#             continue\n",
    "#         print (pic_dir)\n",
    "#         image = load_img(pic_dir)\n",
    "#         image = img_to_array(image)\n",
    "#         image = np.expand_dims(image, axis=0)\n",
    "#         aug = ImageDataGenerator(rotation_range=30, \n",
    "#                                  width_shift_range=0.1,\n",
    "#                                  height_shift_range=0.1, \n",
    "#                                  shear_range=0.1, \n",
    "#                                  zoom_range=0.2,\n",
    "#                                  horizontal_flip=True, \n",
    "#                                  fill_mode=\"nearest\")\n",
    "#         total = 0\n",
    "#         imageGen = aug.flow(image, batch_size=1, \n",
    "#                             save_to_dir=kind_dir,\n",
    "#                             save_prefix=\"pic_plus\", \n",
    "#                             save_format=\"jpg\")\n",
    "#         print (imageGen)\n",
    "#         for image in imageGen:\n",
    "#         # increment our counter\n",
    "#             total += 1\n",
    "#             # if we have reached 4 examples, break from the loop\n",
    "#             if total == 4:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dir=train_plus_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 192, 192, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 192, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 192, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 96, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(256, 256, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 6, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4718848   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               34181     \n",
      "=================================================================\n",
      "Total params: 19,467,717\n",
      "Trainable params: 19,467,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(133, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# lr: float >= 0. 学习率 Learning rate\n",
    "\n",
    "# momentum: float >= 0. 参数更新动量 parameter updates momentum\n",
    "\n",
    "# decay: float >= 0. 学习率每次更新的下降率 Learning rate decay over each update\n",
    "\n",
    "# nesterov: boolean. 是否应用 Nesterov 动量 whether to apply Nesterov momentum\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20417 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n",
      "{'001.Affenpinscher': 0, '002.Afghan_hound': 1, '003.Airedale_terrier': 2, '004.Akita': 3, '005.Alaskan_malamute': 4, '006.American_eskimo_dog': 5, '007.American_foxhound': 6, '008.American_staffordshire_terrier': 7, '009.American_water_spaniel': 8, '010.Anatolian_shepherd_dog': 9, '011.Australian_cattle_dog': 10, '012.Australian_shepherd': 11, '013.Australian_terrier': 12, '014.Basenji': 13, '015.Basset_hound': 14, '016.Beagle': 15, '017.Bearded_collie': 16, '018.Beauceron': 17, '019.Bedlington_terrier': 18, '020.Belgian_malinois': 19, '021.Belgian_sheepdog': 20, '022.Belgian_tervuren': 21, '023.Bernese_mountain_dog': 22, '024.Bichon_frise': 23, '025.Black_and_tan_coonhound': 24, '026.Black_russian_terrier': 25, '027.Bloodhound': 26, '028.Bluetick_coonhound': 27, '029.Border_collie': 28, '030.Border_terrier': 29, '031.Borzoi': 30, '032.Boston_terrier': 31, '033.Bouvier_des_flandres': 32, '034.Boxer': 33, '035.Boykin_spaniel': 34, '036.Briard': 35, '037.Brittany': 36, '038.Brussels_griffon': 37, '039.Bull_terrier': 38, '040.Bulldog': 39, '041.Bullmastiff': 40, '042.Cairn_terrier': 41, '043.Canaan_dog': 42, '044.Cane_corso': 43, '045.Cardigan_welsh_corgi': 44, '046.Cavalier_king_charles_spaniel': 45, '047.Chesapeake_bay_retriever': 46, '048.Chihuahua': 47, '049.Chinese_crested': 48, '050.Chinese_shar-pei': 49, '051.Chow_chow': 50, '052.Clumber_spaniel': 51, '053.Cocker_spaniel': 52, '054.Collie': 53, '055.Curly-coated_retriever': 54, '056.Dachshund': 55, '057.Dalmatian': 56, '058.Dandie_dinmont_terrier': 57, '059.Doberman_pinscher': 58, '060.Dogue_de_bordeaux': 59, '061.English_cocker_spaniel': 60, '062.English_setter': 61, '063.English_springer_spaniel': 62, '064.English_toy_spaniel': 63, '065.Entlebucher_mountain_dog': 64, '066.Field_spaniel': 65, '067.Finnish_spitz': 66, '068.Flat-coated_retriever': 67, '069.French_bulldog': 68, '070.German_pinscher': 69, '071.German_shepherd_dog': 70, '072.German_shorthaired_pointer': 71, '073.German_wirehaired_pointer': 72, '074.Giant_schnauzer': 73, '075.Glen_of_imaal_terrier': 74, '076.Golden_retriever': 75, '077.Gordon_setter': 76, '078.Great_dane': 77, '079.Great_pyrenees': 78, '080.Greater_swiss_mountain_dog': 79, '081.Greyhound': 80, '082.Havanese': 81, '083.Ibizan_hound': 82, '084.Icelandic_sheepdog': 83, '085.Irish_red_and_white_setter': 84, '086.Irish_setter': 85, '087.Irish_terrier': 86, '088.Irish_water_spaniel': 87, '089.Irish_wolfhound': 88, '090.Italian_greyhound': 89, '091.Japanese_chin': 90, '092.Keeshond': 91, '093.Kerry_blue_terrier': 92, '094.Komondor': 93, '095.Kuvasz': 94, '096.Labrador_retriever': 95, '097.Lakeland_terrier': 96, '098.Leonberger': 97, '099.Lhasa_apso': 98, '100.Lowchen': 99, '101.Maltese': 100, '102.Manchester_terrier': 101, '103.Mastiff': 102, '104.Miniature_schnauzer': 103, '105.Neapolitan_mastiff': 104, '106.Newfoundland': 105, '107.Norfolk_terrier': 106, '108.Norwegian_buhund': 107, '109.Norwegian_elkhound': 108, '110.Norwegian_lundehund': 109, '111.Norwich_terrier': 110, '112.Nova_scotia_duck_tolling_retriever': 111, '113.Old_english_sheepdog': 112, '114.Otterhound': 113, '115.Papillon': 114, '116.Parson_russell_terrier': 115, '117.Pekingese': 116, '118.Pembroke_welsh_corgi': 117, '119.Petit_basset_griffon_vendeen': 118, '120.Pharaoh_hound': 119, '121.Plott': 120, '122.Pointer': 121, '123.Pomeranian': 122, '124.Poodle': 123, '125.Portuguese_water_dog': 124, '126.Saint_bernard': 125, '127.Silky_terrier': 126, '128.Smooth_fox_terrier': 127, '129.Tibetan_mastiff': 128, '130.Welsh_springer_spaniel': 129, '131.Wirehaired_pointing_griffon': 130, '132.Xoloitzcuintli': 131, '133.Yorkshire_terrier': 132}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(256, 256),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')\n",
    "validation_generator\n",
    "print(validation_generator.class_indices)\n",
    "np.save('labels.npy', validation_generator.class_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 192, 192, 3)\n",
      "labels batch shape: (20, 133)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 57s 568ms/step - loss: 4.9129 - acc: 0.0215 - val_loss: 4.8231 - val_acc: 0.0207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.82311, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 51s 506ms/step - loss: 4.7347 - acc: 0.0430 - val_loss: 4.6278 - val_acc: 0.0395\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.82311 to 4.62785, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 4.5422 - acc: 0.0715 - val_loss: 4.5593 - val_acc: 0.0582\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.62785 to 4.55935, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 4.3395 - acc: 0.0995 - val_loss: 4.3532 - val_acc: 0.0805\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.55935 to 4.35323, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 52s 518ms/step - loss: 4.1811 - acc: 0.1250 - val_loss: 4.1833 - val_acc: 0.1328\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.35323 to 4.18328, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 4.0363 - acc: 0.1350 - val_loss: 4.0587 - val_acc: 0.1338\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.18328 to 4.05871, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 3.8871 - acc: 0.1685 - val_loss: 3.9068 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.05871 to 3.90683, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 56s 563ms/step - loss: 3.8092 - acc: 0.1690 - val_loss: 3.8032 - val_acc: 0.1458\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.90683 to 3.80322, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 52s 518ms/step - loss: 3.6036 - acc: 0.2060 - val_loss: 3.6779 - val_acc: 0.1902\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.80322 to 3.67789, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 3.5066 - acc: 0.2145 - val_loss: 3.5985 - val_acc: 0.1810\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.67789 to 3.59848, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 3.0744 - acc: 0.3207 - val_loss: 3.4967 - val_acc: 0.2130\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.59848 to 3.49675, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 3.0006 - acc: 0.3415 - val_loss: 3.4174 - val_acc: 0.2077\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.49675 to 3.41740, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 2.8966 - acc: 0.3660 - val_loss: 3.3728 - val_acc: 0.2028\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.41740 to 3.37284, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 2.8165 - acc: 0.3660 - val_loss: 3.3065 - val_acc: 0.2237\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.37284 to 3.30654, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 2.7627 - acc: 0.3800 - val_loss: 3.2877 - val_acc: 0.2178\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.30654 to 3.28765, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.6554 - acc: 0.4070 - val_loss: 3.1858 - val_acc: 0.2453\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.28765 to 3.18585, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 2.6397 - acc: 0.3960 - val_loss: 3.1157 - val_acc: 0.2657\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.18585 to 3.11573, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 2.5888 - acc: 0.4145 - val_loss: 3.1125 - val_acc: 0.2657\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.11573 to 3.11250, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.4954 - acc: 0.4185 - val_loss: 3.0582 - val_acc: 0.2580\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.11250 to 3.05818, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 2.4185 - acc: 0.4500 - val_loss: 2.9962 - val_acc: 0.2800\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.05818 to 2.99621, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 54s 536ms/step - loss: 2.2307 - acc: 0.5258 - val_loss: 2.9899 - val_acc: 0.2764\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.99621 to 2.98992, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 1.9975 - acc: 0.5670 - val_loss: 2.9539 - val_acc: 0.2787\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.98992 to 2.95390, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.9789 - acc: 0.5670 - val_loss: 2.9505 - val_acc: 0.2815\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.95390 to 2.95051, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 1.9777 - acc: 0.5675 - val_loss: 2.9177 - val_acc: 0.2744\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.95051 to 2.91769, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 1.8944 - acc: 0.5745 - val_loss: 2.8597 - val_acc: 0.2813\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.91769 to 2.85975, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 1.8828 - acc: 0.5845 - val_loss: 2.8354 - val_acc: 0.3119\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.85975 to 2.83535, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 1.8562 - acc: 0.5850 - val_loss: 2.8127 - val_acc: 0.3297\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.83535 to 2.81266, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 54s 544ms/step - loss: 1.8356 - acc: 0.5895 - val_loss: 2.7918 - val_acc: 0.2952\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.81266 to 2.79183, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 1.8495 - acc: 0.5645 - val_loss: 2.7315 - val_acc: 0.3189\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.79183 to 2.73145, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 1.7245 - acc: 0.6130 - val_loss: 2.7242 - val_acc: 0.3065\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.73145 to 2.72425, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 1.6449 - acc: 0.6321 - val_loss: 2.6969 - val_acc: 0.3076\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.72425 to 2.69694, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 1.3606 - acc: 0.7240 - val_loss: 2.6731 - val_acc: 0.3159\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.69694 to 2.67306, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 54s 544ms/step - loss: 1.4154 - acc: 0.6935 - val_loss: 2.6645 - val_acc: 0.3271\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.67306 to 2.66447, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.4162 - acc: 0.7065 - val_loss: 2.6975 - val_acc: 0.3268\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66447\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 1.3530 - acc: 0.7355 - val_loss: 2.6542 - val_acc: 0.3286\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.66447 to 2.65416, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 1.4013 - acc: 0.6945 - val_loss: 2.6276 - val_acc: 0.3406\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.65416 to 2.62759, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.3227 - acc: 0.7200 - val_loss: 2.6441 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.62759\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 1.3167 - acc: 0.7185 - val_loss: 2.6211 - val_acc: 0.3252\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.62759 to 2.62111, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 1.3131 - acc: 0.7065 - val_loss: 2.6106 - val_acc: 0.3367\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.62111 to 2.61065, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 1.3098 - acc: 0.7120 - val_loss: 2.6262 - val_acc: 0.3312\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.61065\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 53s 535ms/step - loss: 1.2487 - acc: 0.7222 - val_loss: 2.5494 - val_acc: 0.3470\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.61065 to 2.54937, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 1.0209 - acc: 0.8120 - val_loss: 2.5598 - val_acc: 0.3278\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.54937\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.9494 - acc: 0.8295 - val_loss: 2.5825 - val_acc: 0.3459\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.54937\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.9721 - acc: 0.8170 - val_loss: 2.5551 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.54937\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 0.9710 - acc: 0.8115 - val_loss: 2.5173 - val_acc: 0.3623\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.54937 to 2.51727, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 53s 535ms/step - loss: 0.9820 - acc: 0.8040 - val_loss: 2.5273 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.51727\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 51s 506ms/step - loss: 0.9653 - acc: 0.8080 - val_loss: 2.5078 - val_acc: 0.3538\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.51727 to 2.50781, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 54s 543ms/step - loss: 0.9749 - acc: 0.8045 - val_loss: 2.5027 - val_acc: 0.3645\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.50781 to 2.50274, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.0023 - acc: 0.7835 - val_loss: 2.4726 - val_acc: 0.3683\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.50274 to 2.47261, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 0.9384 - acc: 0.8080 - val_loss: 2.5371 - val_acc: 0.3478\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.47261\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.9002 - acc: 0.8235 - val_loss: 2.4791 - val_acc: 0.3701\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.47261\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 0.6819 - acc: 0.8939 - val_loss: 2.5171 - val_acc: 0.3209\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.47261\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 0.7132 - acc: 0.8800 - val_loss: 2.5274 - val_acc: 0.3397\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.47261\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.6979 - acc: 0.8820 - val_loss: 2.4643 - val_acc: 0.3681\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.47261 to 2.46431, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 54s 544ms/step - loss: 0.6879 - acc: 0.8805 - val_loss: 2.5256 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.46431\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 0.7237 - acc: 0.8780 - val_loss: 2.5163 - val_acc: 0.3551\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.46431\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 0.6591 - acc: 0.8900 - val_loss: 2.4728 - val_acc: 0.3748\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.46431\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 0.6847 - acc: 0.8805 - val_loss: 2.4743 - val_acc: 0.3690\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.46431\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 0.6831 - acc: 0.8755 - val_loss: 2.4497 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.46431 to 2.44970, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 0.6666 - acc: 0.8705 - val_loss: 2.4372 - val_acc: 0.3742\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.44970 to 2.43718, saving model to dogskind_reduce_expand.model.weights.best.hdf5\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 0.6865 - acc: 0.8655 - val_loss: 2.5030 - val_acc: 0.3581\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.43718\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 0.4833 - acc: 0.9393 - val_loss: 2.4584 - val_acc: 0.3813\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.43718\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 0.4934 - acc: 0.9325 - val_loss: 2.4570 - val_acc: 0.3774\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.43718\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 52s 518ms/step - loss: 0.4623 - acc: 0.9455 - val_loss: 2.4978 - val_acc: 0.3664\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.43718\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.4872 - acc: 0.9300 - val_loss: 2.5287 - val_acc: 0.3503\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.43718\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 0.4859 - acc: 0.9310 - val_loss: 2.4738 - val_acc: 0.3829\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.43718\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.4751 - acc: 0.9280 - val_loss: 2.4753 - val_acc: 0.3709\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.43718\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import ImageFile\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=7) \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "checkpointer = ModelCheckpoint(filepath='dogskind_reduce_expand.model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "history = model.fit_generator(train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50, \n",
    "      callbacks=[early_stopping,checkpointer], \n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 0.4816 - acc: 0.9340 - val_loss: 2.5478 - val_acc: 0.3694\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.43718\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 0.4925 - acc: 0.9270 - val_loss: 2.4712 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.43718\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 0.5060 - acc: 0.9290 - val_loss: 2.5130 - val_acc: 0.3636\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.43718\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 0.5012 - acc: 0.9195 - val_loss: 2.4731 - val_acc: 0.3793\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.43718\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 0.4447 - acc: 0.9449 - val_loss: 2.4944 - val_acc: 0.3644\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.43718\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 0.4309 - acc: 0.9455 - val_loss: 2.5108 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.43718\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 0.4377 - acc: 0.9450 - val_loss: 2.4628 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.43718\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 0.4374 - acc: 0.9440 - val_loss: 2.5470 - val_acc: 0.3559\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.43718\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 0.4485 - acc: 0.9310 - val_loss: 2.4952 - val_acc: 0.3607\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.43718\n",
      "Epoch 10/100\n",
      " 31/100 [========>.....................] - ETA: 9s - loss: 0.4163 - acc: 0.9387"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e068def3b1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(train_generator,\n",
    "#       steps_per_epoch=100,\n",
    "#       epochs=100,\n",
    "#       validation_data=validation_generator,\n",
    "#       validation_steps=50, \n",
    "#       callbacks=[early_stopping,checkpointer], \n",
    "#       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('dogskind_reduce_expand.model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 836 images belonging to 133 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.486796505310956, 0.3705882386249654]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.evaluate_generator(test_generator,steps=17, max_queue_size=50, workers=1, use_multiprocessing=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "with open('./0cp.yaml', 'w') as outfile:\n",
    "    outfile.write(yaml_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
